{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbGec4tuFg6-"
   },
   "source": [
    "# Tensorboard and Optuna\n",
    "\n",
    "* PyTorch [website](https://pytorch.org/)\n",
    "* PyTorch [Tutorials](https://pytorch.org/tutorials/)\n",
    "* TensorBoard [website](https://www.tensorflow.org/tensorboard)\n",
    "* PyTorch [Tensorboard](https://pytorch.org/docs/stable/tensorboard.html) docs\n",
    "* PyTorch TensorBoard [Tutorial](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUDm-ClcZmKs"
   },
   "source": [
    "# TensorBoard\n",
    "Load the TensorBoard notebook extension\n",
    "\n",
    "*Enable 3rd party cookies in your browser settings. Use Google Chrome.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8p3Tbx8cWEFA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 20536), started 0:01:09 ago. (Use '!kill 20536' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1f0dfa6b3af2866a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1f0dfa6b3af2866a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "logs_dir = './logs/'\n",
    "%tensorboard --logdir {logs_dir} --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "aF6PfGxJaTk0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"rm\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "#!rm -r {logs_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VG-GsdpUB_Y-"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# writer = SummaryWriter(log_dir=logs_dir+'experiment_02', flush_secs=2)\n",
    "\n",
    "# for epoch in range(1, 100):\n",
    "#     writer.add_scalar('Loss/train', np.random.random()/epoch, epoch)\n",
    "#     writer.add_scalar('Loss/test', np.random.random()/epoch, epoch)\n",
    "#     writer.add_scalar('Accuracy/train', np.random.random()*epoch, epoch)\n",
    "#     writer.add_scalar('Accuracy/test', np.random.random()*epoch, epoch)\n",
    "#     time.sleep(0.25)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2a7FqaIkdd7"
   },
   "source": [
    "## Homework 04\n",
    "\n",
    "\n",
    "All tasks could be done together.\n",
    "1. (3) Use Optuna to tune hyperparameters. Decrease error rate of your best original model (Homework 03) by 20% at least. (E.g., your best model accuracy was 85%, the error rate was 100%-85%=15%; hence, you need to find hyperparameters to achieve 100%-15%*(100%-80%)=88% accuracy)\n",
    "2. (1) Use TensorBoard to log each model training process (Train and Val loss and accuracy) (*.add_scalar*) and save hyperparameters of each model examined by Optuna (*.add_hparams*).\n",
    "3. (1) Save visualization of each model architecture examined by Optuna to TensorBoard. (*.add_graph*)\n",
    "4. \\* (2) Save up to 3 misclassified images from the test dataset of each class of each model architecture examined by Optuna to TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(batch_size=128, num_workers=2, transform=transforms.ToTensor()):\n",
    "    train = datasets.CIFAR10('../data', train=True, download=True, transform=transform)\n",
    "    test = datasets.CIFAR10('../data', train=False, download=True, transform=transform)\n",
    "    torch.manual_seed(123)  # To ensure the same sampling during each experiment\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        #ResNet\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        #Residual block 1\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(16)\n",
    "        self.conv5 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        \n",
    "        #Residual block 2\n",
    "        self.conv6 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(32)\n",
    "        self.conv7 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv8 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv9 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn9 = nn.BatchNorm2d(32)\n",
    "        self.conv10 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn10 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        \n",
    "        #Residual block 3\n",
    "        self.conv11 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn11 = nn.BatchNorm2d(64)\n",
    "        self.conv12 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn12 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv13 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn13 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv14 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn14 = nn.BatchNorm2d(64)\n",
    "        self.conv15 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn15 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        \n",
    "        #Final\n",
    "        self.pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        \n",
    "        #Residual block 1\n",
    "        \n",
    "        residual = x\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x += residual\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        residual = x\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x += residual\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        \n",
    "        #Residual block 2\n",
    "        \n",
    "        residual = x\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.conv7(x)\n",
    "        x = self.bn7(x)\n",
    "        residual = self.conv8(residual)\n",
    "        residual = self.bn8(residual)\n",
    "        x += residual\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        residual = x\n",
    "        x = self.conv9(x)\n",
    "        x = self.bn9(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.conv10(x)\n",
    "        x = self.bn10(x)\n",
    "        x += residual\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        \n",
    "        #Residual block 3\n",
    "        \n",
    "        residual = x\n",
    "        x = self.conv11(x)\n",
    "        x = self.bn11(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.conv12(x)\n",
    "        x = self.bn12(x)\n",
    "        residual = self.conv13(residual)\n",
    "        residual = self.bn13(residual)\n",
    "        x += residual\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        residual = x\n",
    "        x = self.conv14(x)\n",
    "        x = self.bn14(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.conv15(x)\n",
    "        x = self.bn15(x)\n",
    "        x += residual\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        \n",
    "        #Final\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x, 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += F.nll_loss(out, target, reduction='sum').item()\n",
    "        \n",
    "        _, predicted = torch.max(out, 1)\n",
    "        correct += (predicted == target).sum().item()\n",
    "    \n",
    "    return train_loss / len(train_loader.dataset), 100*correct/len(train_loader.dataset)\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            out = model(data)\n",
    "            loss = F.nll_loss(out, target, reduction='sum')\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(out, 1)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "    return test_loss / len(test_loader.dataset), 100*correct/len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты обучения с исходными гиперпараметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 0, train loss: 1.3189632302856444, train accuracy: 51.886, test loss: 1.2484499015808106, test accuracy: 57.32\n",
      "Epoch: 1, train loss: 0.9172500576019287, train accuracy: 67.168, test loss: 0.9936826674461364, test accuracy: 64.68\n",
      "Epoch: 2, train loss: 0.7532615420532227, train accuracy: 73.272, test loss: 1.046308250617981, test accuracy: 62.53\n",
      "Epoch: 3, train loss: 0.644967350616455, train accuracy: 77.394, test loss: 0.7758380510330201, test accuracy: 73.82\n",
      "Epoch: 4, train loss: 0.5712703308105469, train accuracy: 79.84, test loss: 0.6856704473495483, test accuracy: 76.45\n",
      "Epoch: 5, train loss: 0.5108024661254883, train accuracy: 82.124, test loss: 0.6793796546936035, test accuracy: 76.42\n",
      "Epoch: 6, train loss: 0.45692398040771487, train accuracy: 83.92, test loss: 0.7882611918449401, test accuracy: 74.53\n",
      "Epoch: 7, train loss: 0.4108411571884155, train accuracy: 85.634, test loss: 0.6668471819877625, test accuracy: 78.39\n",
      "Epoch: 8, train loss: 0.36785957515716555, train accuracy: 87.09, test loss: 0.7047087820053101, test accuracy: 77.44\n",
      "Epoch: 9, train loss: 0.33318329036712646, train accuracy: 88.186, test loss: 0.7615415050506592, test accuracy: 75.85\n",
      "Epoch: 10, train loss: 0.29440395919799806, train accuracy: 89.684, test loss: 0.7546892329216004, test accuracy: 77.36\n",
      "Epoch: 11, train loss: 0.26215642196655276, train accuracy: 90.91, test loss: 0.7004899103164672, test accuracy: 78.05\n",
      "Epoch: 12, train loss: 0.23188287836074828, train accuracy: 91.766, test loss: 0.7158410621643067, test accuracy: 78.03\n",
      "Epoch: 13, train loss: 0.2020692861557007, train accuracy: 92.966, test loss: 0.7703563450813293, test accuracy: 77.09\n",
      "Epoch: 14, train loss: 0.18085738620758057, train accuracy: 93.656, test loss: 0.7490652209281922, test accuracy: 78.76\n",
      "Epoch: 15, train loss: 0.15676496597290038, train accuracy: 94.5, test loss: 0.8730448474884033, test accuracy: 77.0\n",
      "Epoch: 16, train loss: 0.13384403161048888, train accuracy: 95.448, test loss: 0.949084369468689, test accuracy: 77.36\n",
      "Epoch: 17, train loss: 0.12016703790664673, train accuracy: 95.864, test loss: 0.992792893409729, test accuracy: 76.09\n",
      "Epoch: 18, train loss: 0.10425108751296996, train accuracy: 96.412, test loss: 1.0309946853637695, test accuracy: 75.12\n",
      "Epoch: 19, train loss: 0.10703386196613311, train accuracy: 96.372, test loss: 0.8349101675033569, test accuracy: 79.14\n",
      "Epoch: 20, train loss: 0.09302773735046387, train accuracy: 96.83, test loss: 0.8738814754486084, test accuracy: 78.94\n",
      "Epoch: 21, train loss: 0.09493494837760925, train accuracy: 96.654, test loss: 1.0049884126663209, test accuracy: 78.17\n",
      "Model doesn't improve, early stop\n"
     ]
    }
   ],
   "source": [
    "epochs = 80\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_loader, test_loader = get_loaders(batch_size=batch_size, transform=transform, num_workers=0)\n",
    "model = ResNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max')\n",
    "\n",
    "min_loss = 100\n",
    "max_early_stop = 15\n",
    "early_stop = 0\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_accuracy = train(model, device, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = test(model, device, test_loader)\n",
    "    scheduler.step(test_accuracy)\n",
    "\n",
    "    #early stop\n",
    "    if test_loss > min_loss:\n",
    "        early_stop += 1\n",
    "    else:\n",
    "        min_loss = test_loss\n",
    "        early_stop = 0\n",
    "    if early_stop == max_early_stop:\n",
    "        print(\"Model doesn't improve, early stop\")\n",
    "        break\n",
    "\n",
    "\n",
    "    print(\"Epoch: {}, train loss: {}, train accuracy: {}, test loss: {}, test accuracy: {}\".format(epoch, train_loss, train_accuracy, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(100%-78%)*0.2 = 4.4%\n",
    "Требуется увеличить значение точности на 4.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск потимальных гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_len = 20000\n",
    "test_split_len = 5000\n",
    "\n",
    "def get_loaders_batch(batch_size=128, num_workers=2, transform=transforms.ToTensor()):\n",
    "    train = datasets.CIFAR10('../data', train=True, download=True, transform=transform)\n",
    "    test = datasets.CIFAR10('../data', train=False, download=True, transform=transform)\n",
    "    torch.manual_seed(123)  # To ensure the same sampling during each experiment\n",
    "    train = torch.utils.data.random_split(train, [train_split_len, len(train)-train_split_len])[0]\n",
    "    test = torch.utils.data.random_split(test, [test_split_len, len(test)-test_split_len])[0]\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты на части датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 0, train loss: 1.5943648639678956, train accuracy: 41.365, test loss: 1.5803111841201782, test accuracy: 43.06\n",
      "Epoch: 1, train loss: 1.2028879693984986, train accuracy: 56.365, test loss: 1.3263910757064818, test accuracy: 54.04\n",
      "Epoch: 2, train loss: 1.016085764312744, train accuracy: 63.55, test loss: 1.7451686050415038, test accuracy: 44.4\n",
      "Epoch: 3, train loss: 0.9019544897079468, train accuracy: 67.445, test loss: 1.0092890419006348, test accuracy: 63.56\n",
      "Epoch: 4, train loss: 0.7993814951896667, train accuracy: 71.49, test loss: 1.4173109228134155, test accuracy: 55.8\n",
      "Epoch: 5, train loss: 0.7183253150939941, train accuracy: 74.62, test loss: 1.111238115310669, test accuracy: 61.44\n",
      "Epoch: 6, train loss: 0.6358985503196717, train accuracy: 77.475, test loss: 1.0777069185256958, test accuracy: 63.18\n",
      "Epoch: 7, train loss: 0.5653978249549866, train accuracy: 80.4, test loss: 1.3068972537994386, test accuracy: 59.42\n",
      "Epoch: 8, train loss: 0.5041300978660583, train accuracy: 82.49, test loss: 0.932657177734375, test accuracy: 69.42\n",
      "Epoch: 9, train loss: 0.4328163990020752, train accuracy: 85.48, test loss: 1.3241028380393982, test accuracy: 61.24\n",
      "Epoch: 10, train loss: 0.38443066120147706, train accuracy: 86.855, test loss: 1.3078313116073608, test accuracy: 62.72\n",
      "Epoch: 11, train loss: 0.3207913681507111, train accuracy: 89.345, test loss: 1.0541683542251588, test accuracy: 68.18\n",
      "Epoch: 12, train loss: 0.26856331748962403, train accuracy: 91.25, test loss: 1.2973394315719604, test accuracy: 65.0\n",
      "Epoch: 13, train loss: 0.24083687582015992, train accuracy: 92.01, test loss: 1.1803652418136596, test accuracy: 66.72\n",
      "Epoch: 14, train loss: 0.1994904348373413, train accuracy: 93.535, test loss: 1.7643867692947388, test accuracy: 60.6\n",
      "Epoch: 15, train loss: 0.15219188208580017, train accuracy: 95.265, test loss: 1.2650526178836823, test accuracy: 66.12\n",
      "Epoch: 16, train loss: 0.14100861809253692, train accuracy: 95.585, test loss: 1.8842028316497803, test accuracy: 61.6\n",
      "Epoch: 17, train loss: 0.12091918680667878, train accuracy: 96.24, test loss: 1.460112441444397, test accuracy: 67.72\n",
      "Epoch: 18, train loss: 0.09536479122638702, train accuracy: 97.095, test loss: 1.3115093774795532, test accuracy: 68.12\n",
      "Epoch: 19, train loss: 0.1173687185883522, train accuracy: 96.045, test loss: 1.60095498046875, test accuracy: 64.54\n",
      "Epoch: 20, train loss: 0.04290799419283867, train accuracy: 99.05, test loss: 1.0615704686164855, test accuracy: 72.62\n",
      "Epoch: 21, train loss: 0.021637723141908646, train accuracy: 99.83, test loss: 1.0606831819534301, test accuracy: 73.1\n",
      "Epoch: 22, train loss: 0.016451111832261084, train accuracy: 99.975, test loss: 1.058345976114273, test accuracy: 72.96\n",
      "Model doesn't improve, early stop\n"
     ]
    }
   ],
   "source": [
    "epochs = 80\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_loader, test_loader = get_loaders_batch(batch_size=batch_size, transform=transform, num_workers=0)\n",
    "model = ResNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max')\n",
    "\n",
    "min_loss = 128\n",
    "max_early_stop = 15\n",
    "early_stop = 0\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_accuracy = train(model, device, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = test(model, device, test_loader)\n",
    "    scheduler.step(test_accuracy)\n",
    "\n",
    "    #early stop\n",
    "    if test_loss > min_loss:\n",
    "        early_stop += 1\n",
    "    else:\n",
    "        min_loss = test_loss\n",
    "        early_stop = 0\n",
    "    if early_stop == max_early_stop:\n",
    "        print(\"Model doesn't improve, early stop\")\n",
    "        break\n",
    "\n",
    "\n",
    "    print(\"Epoch: {}, train loss: {}, train accuracy: {}, test loss: {}, test accuracy: {}\".format(epoch, train_loss, train_accuracy, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#отдельная функция трейна с эпохами\n",
    "\n",
    "def epoch_train(model, params, trial_n):\n",
    "    \n",
    "    experiment = 'trial_'+str(trial_n)\n",
    "    writer = SummaryWriter(log_dir=logs_dir+experiment, flush_secs=2)\n",
    "    \n",
    "    epochs = 80\n",
    "    max_early_stop = 15\n",
    "    min_loss = 100\n",
    "    early_stop = 0\n",
    "    batch_size = 128\n",
    "    \n",
    "    lr = params[\"lr\"]\n",
    "    weight_decay = params[\"weight_decay\"]\n",
    "    amsgrad = params[\"amsgrad\"]\n",
    "    patience = params[\"patience\"]\n",
    "    \n",
    "    train_loader, test_loader = get_loaders_batch(batch_size=batch_size, transform=transform, num_workers=0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = weight_decay, amsgrad = amsgrad)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'max', patience = patience)\n",
    "    \n",
    "    accuracy = 0\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_accuracy = train(model, device, train_loader, optimizer)\n",
    "        test_loss, test_accuracy = test(model, device, test_loader)\n",
    "        scheduler.step(test_accuracy)\n",
    "        \n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/test', test_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', train_accuracy, epoch)\n",
    "        writer.add_scalar('Accuracy/test', test_accuracy, epoch)\n",
    "\n",
    "        #early stop\n",
    "        if test_loss > min_loss:\n",
    "            early_stop += 1\n",
    "        else:\n",
    "            min_loss = test_loss\n",
    "            early_stop = 0\n",
    "        if early_stop == max_early_stop:\n",
    "            print(\"Model doesn't improve, early stop\")\n",
    "            accuracy = test_accuracy\n",
    "            break\n",
    "        if epoch==epochs-1:\n",
    "            accuracy = test_accuracy\n",
    "    \n",
    "    writer.add_hparams(hparam_dict = params, metric_dict = {'accuracy':accuracy})\n",
    "    writer.close()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6iwPRszakdeG"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "model = ResNet().to(device)\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    amsgrad = trial.suggest_categorical(\"amsgrad\",[True, False])\n",
    "    lr = trial.suggest_categorical(\"lr\", [1e-5, 1e-4, 1e-3, 1e-2, 1e-1])\n",
    "    weight_decay = trial.suggest_categorical(\"weight_decay\", [0, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1])\n",
    "    patience = trial.suggest_int(\"patience\", 4, 10)\n",
    "    \n",
    "    params = {\"lr\":1e-3, \"weight_decay\":weight_decay, \"amsgrad\": amsgrad, \"patience\": patience}\n",
    "    \n",
    "    accuracy = epoch_train(model, params, trial.number)\n",
    "    \n",
    "    print(accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-12 23:28:22,188]\u001b[0m A new study created in memory with name: no-name-ec8d6f35-0672-45b1-9d83-cf4bae8830c3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-12 23:36:32,733]\u001b[0m Trial 0 finished with value: 74.28 and parameters: {'amsgrad': True, 'lr': 0.0001, 'weight_decay': 0, 'patience': 10}. Best is trial 0 with value: 74.28.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.28\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-12 23:46:52,518]\u001b[0m Trial 1 finished with value: 74.84 and parameters: {'amsgrad': True, 'lr': 0.001, 'weight_decay': 1e-06, 'patience': 9}. Best is trial 1 with value: 74.84.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.84\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 00:03:38,998]\u001b[0m Trial 2 finished with value: 74.96 and parameters: {'amsgrad': True, 'lr': 0.1, 'weight_decay': 0.001, 'patience': 7}. Best is trial 2 with value: 74.96.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.96\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 00:20:14,998]\u001b[0m Trial 3 finished with value: 73.3 and parameters: {'amsgrad': False, 'lr': 0.001, 'weight_decay': 0.1, 'patience': 9}. Best is trial 2 with value: 74.96.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "73.3\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 00:28:32,937]\u001b[0m Trial 4 finished with value: 71.72 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 1e-06, 'patience': 9}. Best is trial 2 with value: 74.96.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "71.72\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 00:38:08,051]\u001b[0m Trial 5 finished with value: 76.48 and parameters: {'amsgrad': False, 'lr': 0.001, 'weight_decay': 0.0001, 'patience': 5}. Best is trial 5 with value: 76.48.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "76.48\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 00:47:05,691]\u001b[0m Trial 6 finished with value: 76.68 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 0.0001, 'patience': 7}. Best is trial 6 with value: 76.68.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "76.68\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 00:59:52,322]\u001b[0m Trial 7 finished with value: 77.84 and parameters: {'amsgrad': True, 'lr': 1e-05, 'weight_decay': 0.1, 'patience': 6}. Best is trial 7 with value: 77.84.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "77.84\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 01:05:57,755]\u001b[0m Trial 8 finished with value: 76.0 and parameters: {'amsgrad': True, 'lr': 0.001, 'weight_decay': 1e-05, 'patience': 4}. Best is trial 7 with value: 77.84.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "76.0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 01:13:37,963]\u001b[0m Trial 9 finished with value: 77.8 and parameters: {'amsgrad': False, 'lr': 0.0001, 'weight_decay': 0.0001, 'patience': 5}. Best is trial 7 with value: 77.84.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "77.8\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 01:27:21,676]\u001b[0m Trial 10 finished with value: 78.56 and parameters: {'amsgrad': True, 'lr': 0.01, 'weight_decay': 0.1, 'patience': 6}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "78.56\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 01:43:38,599]\u001b[0m Trial 11 finished with value: 74.64 and parameters: {'amsgrad': True, 'lr': 0.01, 'weight_decay': 0.1, 'patience': 6}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.64\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 01:51:57,022]\u001b[0m Trial 12 finished with value: 72.78 and parameters: {'amsgrad': True, 'lr': 0.01, 'weight_decay': 1e-07, 'patience': 6}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "72.78\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 02:00:55,518]\u001b[0m Trial 13 finished with value: 75.52 and parameters: {'amsgrad': True, 'lr': 0.01, 'weight_decay': 0.01, 'patience': 6}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "75.52\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 02:18:28,919]\u001b[0m Trial 14 finished with value: 74.84 and parameters: {'amsgrad': True, 'lr': 1e-05, 'weight_decay': 0.1, 'patience': 4}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.84\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 02:37:16,146]\u001b[0m Trial 15 finished with value: 74.28 and parameters: {'amsgrad': True, 'lr': 0.1, 'weight_decay': 0.1, 'patience': 8}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.28\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 02:52:33,200]\u001b[0m Trial 16 finished with value: 74.74 and parameters: {'amsgrad': True, 'lr': 0.01, 'weight_decay': 0.1, 'patience': 5}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.74\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 03:03:41,935]\u001b[0m Trial 17 finished with value: 75.04 and parameters: {'amsgrad': True, 'lr': 1e-05, 'weight_decay': 0.01, 'patience': 7}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "75.04\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 03:09:26,007]\u001b[0m Trial 18 finished with value: 68.22 and parameters: {'amsgrad': True, 'lr': 1e-05, 'weight_decay': 0, 'patience': 6}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "68.22\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 03:14:39,037]\u001b[0m Trial 19 finished with value: 71.78 and parameters: {'amsgrad': True, 'lr': 0.01, 'weight_decay': 1e-05, 'patience': 8}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "71.78\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 03:24:49,970]\u001b[0m Trial 20 finished with value: 74.48 and parameters: {'amsgrad': True, 'lr': 1e-05, 'weight_decay': 1e-07, 'patience': 5}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.48\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 03:33:05,866]\u001b[0m Trial 21 finished with value: 74.24 and parameters: {'amsgrad': False, 'lr': 0.0001, 'weight_decay': 0.0001, 'patience': 5}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.24\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 03:45:48,659]\u001b[0m Trial 22 finished with value: 74.82 and parameters: {'amsgrad': False, 'lr': 0.0001, 'weight_decay': 0.1, 'patience': 4}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.82\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 03:53:45,725]\u001b[0m Trial 23 finished with value: 76.26 and parameters: {'amsgrad': False, 'lr': 0.0001, 'weight_decay': 0.0001, 'patience': 6}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "76.26\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 03:59:11,666]\u001b[0m Trial 24 finished with value: 75.88 and parameters: {'amsgrad': False, 'lr': 0.0001, 'weight_decay': 0.1, 'patience': 5}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "75.88\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 04:05:34,561]\u001b[0m Trial 25 finished with value: 66.22 and parameters: {'amsgrad': False, 'lr': 0.1, 'weight_decay': 0.001, 'patience': 6}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "66.22\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 04:13:34,494]\u001b[0m Trial 26 finished with value: 75.82 and parameters: {'amsgrad': True, 'lr': 0.0001, 'weight_decay': 0.0001, 'patience': 5}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "75.82\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 04:31:02,022]\u001b[0m Trial 27 finished with value: 75.08 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.1, 'patience': 7}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "75.08\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 04:38:58,200]\u001b[0m Trial 28 finished with value: 73.24 and parameters: {'amsgrad': True, 'lr': 0.01, 'weight_decay': 0, 'patience': 8}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "73.24\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 04:48:33,634]\u001b[0m Trial 29 finished with value: 78.16 and parameters: {'amsgrad': True, 'lr': 0.0001, 'weight_decay': 0.1, 'patience': 4}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "78.16\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 05:07:29,057]\u001b[0m Trial 30 finished with value: 74.28 and parameters: {'amsgrad': True, 'lr': 1e-05, 'weight_decay': 0.1, 'patience': 4}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.28\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 05:24:58,918]\u001b[0m Trial 31 finished with value: 74.78 and parameters: {'amsgrad': True, 'lr': 0.0001, 'weight_decay': 0.1, 'patience': 4}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.78\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 05:37:22,873]\u001b[0m Trial 32 finished with value: 76.34 and parameters: {'amsgrad': True, 'lr': 0.0001, 'weight_decay': 1e-06, 'patience': 5}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "76.34\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 05:45:20,790]\u001b[0m Trial 33 finished with value: 75.12 and parameters: {'amsgrad': True, 'lr': 0.0001, 'weight_decay': 0.001, 'patience': 6}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "75.12\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 05:57:08,509]\u001b[0m Trial 34 finished with value: 75.32 and parameters: {'amsgrad': True, 'lr': 0.0001, 'weight_decay': 0.1, 'patience': 5}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "75.32\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 06:14:39,519]\u001b[0m Trial 35 finished with value: 74.62 and parameters: {'amsgrad': True, 'lr': 0.0001, 'weight_decay': 0.1, 'patience': 6}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.62\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 06:24:12,387]\u001b[0m Trial 36 finished with value: 76.58 and parameters: {'amsgrad': False, 'lr': 0.1, 'weight_decay': 1e-06, 'patience': 4}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "76.58\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 06:32:30,717]\u001b[0m Trial 37 finished with value: 75.3 and parameters: {'amsgrad': True, 'lr': 0.001, 'weight_decay': 0.0001, 'patience': 7}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "75.3\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 06:39:13,169]\u001b[0m Trial 38 finished with value: 72.82 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 1e-05, 'patience': 10}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "72.82\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 06:47:31,005]\u001b[0m Trial 39 finished with value: 74.96 and parameters: {'amsgrad': True, 'lr': 0.0001, 'weight_decay': 1e-07, 'patience': 5}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.96\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 06:55:10,367]\u001b[0m Trial 40 finished with value: 74.74 and parameters: {'amsgrad': False, 'lr': 0.001, 'weight_decay': 0.01, 'patience': 6}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.74\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 07:04:06,222]\u001b[0m Trial 41 finished with value: 74.68 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 0.0001, 'patience': 7}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.68\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 07:10:52,739]\u001b[0m Trial 42 finished with value: 71.58 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 0.0001, 'patience': 8}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "71.58\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Model doesn't improve, early stop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 07:19:11,598]\u001b[0m Trial 43 finished with value: 74.2 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 0.0001, 'patience': 7}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.2\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 07:28:46,091]\u001b[0m Trial 44 finished with value: 74.56 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 0.0001, 'patience': 6}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.56\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 07:34:53,122]\u001b[0m Trial 45 finished with value: 58.56 and parameters: {'amsgrad': True, 'lr': 0.01, 'weight_decay': 0.1, 'patience': 7}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "58.56\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 07:46:39,600]\u001b[0m Trial 46 finished with value: 76.56 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 0, 'patience': 6}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "76.56\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Model doesn't improve, early stop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 07:52:05,717]\u001b[0m Trial 47 finished with value: 76.06 and parameters: {'amsgrad': True, 'lr': 0.01, 'weight_decay': 0.1, 'patience': 4}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.06\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 08:06:31,547]\u001b[0m Trial 48 finished with value: 76.46 and parameters: {'amsgrad': True, 'lr': 0.1, 'weight_decay': 0.0001, 'patience': 5}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "76.46\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 08:24:04,818]\u001b[0m Trial 49 finished with value: 77.3 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 0.1, 'patience': 7}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "77.3\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 08:41:41,253]\u001b[0m Trial 50 finished with value: 74.84 and parameters: {'amsgrad': True, 'lr': 1e-05, 'weight_decay': 0.1, 'patience': 6}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.84\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 09:01:07,805]\u001b[0m Trial 51 finished with value: 74.6 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 0.1, 'patience': 8}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "74.6\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 09:18:41,858]\u001b[0m Trial 52 finished with value: 73.78 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 0.1, 'patience': 7}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "73.78\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Model doesn't improve, early stop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 09:36:32,298]\u001b[0m Trial 53 finished with value: 74.58 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 0.1, 'patience': 7}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74.58\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 09:44:00,668]\u001b[0m Trial 54 finished with value: 70.46 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 1e-05, 'patience': 8}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "70.46\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 09:52:32,614]\u001b[0m Trial 55 finished with value: 75.02 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.01, 'patience': 7}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "75.02\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Model doesn't improve, early stop\n",
      "69.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 10:00:26,766]\u001b[0m Trial 56 finished with value: 69.8 and parameters: {'amsgrad': False, 'lr': 0.0001, 'weight_decay': 0.001, 'patience': 6}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 10:07:05,730]\u001b[0m Trial 57 finished with value: 75.16 and parameters: {'amsgrad': True, 'lr': 0.001, 'weight_decay': 1e-07, 'patience': 5}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "75.16\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Model doesn't improve, early stop\n",
      "74.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 10:16:34,187]\u001b[0m Trial 58 finished with value: 74.84 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 0.1, 'patience': 7}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-13 10:28:23,400]\u001b[0m Trial 59 finished with value: 75.08 and parameters: {'amsgrad': True, 'lr': 0.01, 'weight_decay': 0.0001, 'patience': 6}. Best is trial 10 with value: 78.56.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "75.08\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials = 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперпараметры, выдающие лучший результат согласно тестам optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 0, train loss: 2.1087148974609375, train accuracy: 19.332, test loss: 2.2405940105438233, test accuracy: 11.39\n",
      "Epoch: 1, train loss: 2.1456982568359373, train accuracy: 17.95, test loss: 2.2152142162322996, test accuracy: 14.78\n",
      "Epoch: 2, train loss: 2.1216576470947266, train accuracy: 17.988, test loss: 2.1491609413146975, test accuracy: 16.61\n",
      "Epoch: 3, train loss: 2.0957974383544924, train accuracy: 17.94, test loss: 2.1846366706848146, test accuracy: 14.61\n",
      "Epoch: 4, train loss: 2.091106525268555, train accuracy: 18.064, test loss: 2.197235676574707, test accuracy: 14.08\n",
      "Epoch: 5, train loss: 2.0865254098510744, train accuracy: 18.292, test loss: 2.0958155609130857, test accuracy: 16.47\n",
      "Epoch: 6, train loss: 2.081383836669922, train accuracy: 18.134, test loss: 2.483316763687134, test accuracy: 10.04\n",
      "Epoch: 7, train loss: 2.082813187866211, train accuracy: 17.96, test loss: 2.063861925125122, test accuracy: 17.46\n",
      "Epoch: 8, train loss: 2.084135072937012, train accuracy: 17.806, test loss: 2.321813843917847, test accuracy: 10.89\n",
      "Epoch: 9, train loss: 2.0839370419311525, train accuracy: 18.166, test loss: 2.0843318283081054, test accuracy: 17.24\n",
      "Epoch: 10, train loss: 2.080590837402344, train accuracy: 18.358, test loss: 2.1626359519958496, test accuracy: 15.78\n",
      "Epoch: 11, train loss: 2.081003876953125, train accuracy: 18.192, test loss: 2.174070838546753, test accuracy: 14.45\n",
      "Epoch: 12, train loss: 2.0806811029052734, train accuracy: 17.984, test loss: 2.1645516040802, test accuracy: 15.11\n",
      "Epoch: 13, train loss: 2.08165268951416, train accuracy: 18.004, test loss: 2.7268514442443847, test accuracy: 10.03\n",
      "Epoch: 14, train loss: 2.0791573904418947, train accuracy: 18.246, test loss: 2.2810872245788576, test accuracy: 12.96\n",
      "Epoch: 15, train loss: 2.053469253234863, train accuracy: 18.414, test loss: 2.0694244220733644, test accuracy: 17.39\n",
      "Epoch: 16, train loss: 2.04759274597168, train accuracy: 18.456, test loss: 2.0397854545593264, test accuracy: 18.72\n",
      "Epoch: 17, train loss: 2.0460075381469727, train accuracy: 18.626, test loss: 2.066630645751953, test accuracy: 17.72\n",
      "Epoch: 18, train loss: 2.046169475708008, train accuracy: 18.462, test loss: 2.0398330070495607, test accuracy: 18.86\n",
      "Epoch: 19, train loss: 2.046217084350586, train accuracy: 18.292, test loss: 2.0552172916412355, test accuracy: 17.81\n",
      "Epoch: 20, train loss: 2.046723687744141, train accuracy: 18.302, test loss: 2.0361365730285645, test accuracy: 18.1\n",
      "Epoch: 21, train loss: 2.044303179626465, train accuracy: 18.554, test loss: 2.0557838432312012, test accuracy: 18.45\n",
      "Epoch: 22, train loss: 2.0450803189086915, train accuracy: 18.428, test loss: 2.06146667098999, test accuracy: 17.84\n",
      "Epoch: 23, train loss: 2.045504521789551, train accuracy: 18.464, test loss: 2.043225975418091, test accuracy: 18.25\n",
      "Epoch: 24, train loss: 2.046030841369629, train accuracy: 18.55, test loss: 2.084125088882446, test accuracy: 17.91\n",
      "Epoch: 25, train loss: 2.0440511724853514, train accuracy: 18.522, test loss: 2.2237738971710206, test accuracy: 13.67\n",
      "Epoch: 26, train loss: 2.040022589111328, train accuracy: 18.658, test loss: 2.037548607635498, test accuracy: 18.86\n",
      "Epoch: 27, train loss: 2.0382405520629883, train accuracy: 18.712, test loss: 2.0389369575500487, test accuracy: 18.4\n",
      "Epoch: 28, train loss: 2.0373818478393555, train accuracy: 18.608, test loss: 2.031650742340088, test accuracy: 18.71\n",
      "Epoch: 29, train loss: 2.037184662475586, train accuracy: 18.604, test loss: 2.032750593185425, test accuracy: 18.61\n",
      "Epoch: 30, train loss: 2.036804288635254, train accuracy: 18.716, test loss: 2.0364578994750975, test accuracy: 18.92\n",
      "Epoch: 31, train loss: 2.0364879306030272, train accuracy: 18.596, test loss: 2.035567795944214, test accuracy: 18.41\n",
      "Epoch: 32, train loss: 2.036035244140625, train accuracy: 18.492, test loss: 2.0323898838043215, test accuracy: 18.42\n",
      "Epoch: 33, train loss: 2.035758186645508, train accuracy: 18.58, test loss: 2.029019394683838, test accuracy: 18.69\n",
      "Epoch: 34, train loss: 2.034746824951172, train accuracy: 18.564, test loss: 2.0315480640411376, test accuracy: 18.74\n",
      "Epoch: 35, train loss: 2.035113914794922, train accuracy: 18.582, test loss: 2.0299003215789795, test accuracy: 18.66\n",
      "Epoch: 36, train loss: 2.0348243072509766, train accuracy: 18.608, test loss: 2.0292411922454834, test accuracy: 18.71\n",
      "Epoch: 37, train loss: 2.034806907348633, train accuracy: 18.514, test loss: 2.050847494506836, test accuracy: 18.47\n",
      "Epoch: 38, train loss: 2.0339175170898436, train accuracy: 18.622, test loss: 2.0325675231933595, test accuracy: 18.69\n",
      "Epoch: 39, train loss: 2.0340503170776367, train accuracy: 18.606, test loss: 2.0291433086395263, test accuracy: 18.72\n",
      "Epoch: 40, train loss: 2.03338841217041, train accuracy: 18.61, test loss: 2.0300702713012697, test accuracy: 18.72\n",
      "Epoch: 41, train loss: 2.0336854638671875, train accuracy: 18.55, test loss: 2.031287963104248, test accuracy: 18.61\n",
      "Epoch: 42, train loss: 2.0333726184082033, train accuracy: 18.618, test loss: 2.029529972076416, test accuracy: 18.74\n",
      "Epoch: 43, train loss: 2.0334282974243165, train accuracy: 18.534, test loss: 2.029678084182739, test accuracy: 18.78\n",
      "Epoch: 44, train loss: 2.0329320529174804, train accuracy: 18.67, test loss: 2.0294068492889403, test accuracy: 18.85\n",
      "Epoch: 45, train loss: 2.033107264709473, train accuracy: 18.66, test loss: 2.029250983428955, test accuracy: 18.78\n",
      "Epoch: 46, train loss: 2.032985810852051, train accuracy: 18.652, test loss: 2.029413748550415, test accuracy: 18.75\n",
      "Epoch: 47, train loss: 2.0329579736328127, train accuracy: 18.648, test loss: 2.029925173187256, test accuracy: 18.69\n",
      "Model doesn't improve, early stop\n"
     ]
    }
   ],
   "source": [
    "def get_loaders(batch_size=128, num_workers=2, transform=transforms.ToTensor()):\n",
    "    train = datasets.CIFAR10('../data', train=True, download=True, transform=transform)\n",
    "    test = datasets.CIFAR10('../data', train=False, download=True, transform=transform)\n",
    "    torch.manual_seed(123)  # To ensure the same sampling during each experiment\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "epochs = 80\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_loader, test_loader = get_loaders(batch_size=batch_size, transform=transform, num_workers=0)\n",
    "model = ResNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay = 0.1, amsgrad = True)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max', patience = 6)\n",
    "\n",
    "min_loss = 100\n",
    "max_early_stop = 15\n",
    "early_stop = 0\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_accuracy = train(model, device, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = test(model, device, test_loader)\n",
    "    scheduler.step(test_accuracy)\n",
    "\n",
    "    #early stop\n",
    "    if test_loss > min_loss:\n",
    "        early_stop += 1\n",
    "    else:\n",
    "        min_loss = test_loss\n",
    "        early_stop = 0\n",
    "    if early_stop == max_early_stop:\n",
    "        print(\"Model doesn't improve, early stop\")\n",
    "        break\n",
    "\n",
    "\n",
    "    print(\"Epoch: {}, train loss: {}, train accuracy: {}, test loss: {}, test accuracy: {}\".format(epoch, train_loss, train_accuracy, test_loss, test_accuracy))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй по точноти результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 0, train loss: 1.7348911715698243, train accuracy: 37.376, test loss: 1.4607028423309327, test accuracy: 46.93\n",
      "Epoch: 1, train loss: 1.3391730519104004, train accuracy: 52.452, test loss: 1.2772051935195923, test accuracy: 55.88\n",
      "Epoch: 2, train loss: 1.1522341136169434, train accuracy: 60.132, test loss: 1.1838129133224486, test accuracy: 59.5\n",
      "Epoch: 3, train loss: 1.0477635551452638, train accuracy: 64.196, test loss: 1.1413270091056824, test accuracy: 59.96\n",
      "Epoch: 4, train loss: 0.9740360813903809, train accuracy: 67.398, test loss: 1.098311243057251, test accuracy: 62.24\n",
      "Epoch: 5, train loss: 0.9171803987121582, train accuracy: 69.956, test loss: 1.0977614736557006, test accuracy: 61.53\n",
      "Epoch: 6, train loss: 0.8683072491455078, train accuracy: 72.078, test loss: 0.9804579916000367, test accuracy: 66.62\n",
      "Epoch: 7, train loss: 0.8270677038574219, train accuracy: 73.856, test loss: 0.9155941962242127, test accuracy: 68.98\n",
      "Epoch: 8, train loss: 0.7891499438476562, train accuracy: 75.544, test loss: 0.9130481729507446, test accuracy: 70.01\n",
      "Epoch: 9, train loss: 0.7657707087707519, train accuracy: 76.64, test loss: 0.8905148708343505, test accuracy: 71.05\n",
      "Epoch: 10, train loss: 0.7378071321105957, train accuracy: 78.268, test loss: 0.8553098745346069, test accuracy: 72.5\n",
      "Epoch: 11, train loss: 0.7250214200592041, train accuracy: 78.786, test loss: 0.9584267543792725, test accuracy: 67.61\n",
      "Epoch: 12, train loss: 0.7070563267517089, train accuracy: 79.734, test loss: 0.8433069305419922, test accuracy: 74.0\n",
      "Epoch: 13, train loss: 0.7010695158386231, train accuracy: 80.098, test loss: 0.8586150538444519, test accuracy: 73.17\n",
      "Epoch: 14, train loss: 0.6867820004272461, train accuracy: 81.054, test loss: 0.8379810706138611, test accuracy: 74.05\n",
      "Epoch: 15, train loss: 0.6827123722839356, train accuracy: 81.434, test loss: 0.8939218399047851, test accuracy: 72.07\n",
      "Epoch: 16, train loss: 0.6759627764892578, train accuracy: 81.954, test loss: 0.8462730416297912, test accuracy: 73.34\n",
      "Epoch: 17, train loss: 0.6718639894104004, train accuracy: 82.472, test loss: 0.9036122638702393, test accuracy: 71.34\n",
      "Epoch: 18, train loss: 0.6698757517242432, train accuracy: 82.876, test loss: 0.8398597954750061, test accuracy: 74.14\n",
      "Epoch: 19, train loss: 0.6701373049163818, train accuracy: 83.05, test loss: 0.8761834721565247, test accuracy: 74.14\n",
      "Epoch: 20, train loss: 0.6684208544921875, train accuracy: 83.522, test loss: 0.8831952262878418, test accuracy: 73.71\n",
      "Epoch: 21, train loss: 0.6737218992614746, train accuracy: 83.472, test loss: 0.8373352691650391, test accuracy: 74.45\n",
      "Epoch: 22, train loss: 0.6714002513122559, train accuracy: 83.908, test loss: 0.9322551598548889, test accuracy: 71.06\n",
      "Epoch: 23, train loss: 0.674701741027832, train accuracy: 84.11, test loss: 0.8924927654266357, test accuracy: 72.94\n",
      "Epoch: 24, train loss: 0.6782551480102539, train accuracy: 84.254, test loss: 0.9350456674575806, test accuracy: 72.13\n",
      "Epoch: 25, train loss: 0.6786281981658936, train accuracy: 84.596, test loss: 0.839314861869812, test accuracy: 76.15\n",
      "Epoch: 26, train loss: 0.6823171364593505, train accuracy: 84.758, test loss: 0.8935134159088135, test accuracy: 74.68\n",
      "Epoch: 27, train loss: 0.6850816115570069, train accuracy: 84.966, test loss: 0.9015950740814209, test accuracy: 73.81\n",
      "Epoch: 28, train loss: 0.6889303533935547, train accuracy: 84.984, test loss: 0.8368607486724854, test accuracy: 76.21\n",
      "Epoch: 29, train loss: 0.6959646131896973, train accuracy: 84.98, test loss: 0.9785336494445801, test accuracy: 69.29\n",
      "Epoch: 30, train loss: 0.6981079438781739, train accuracy: 85.21, test loss: 0.8821737798690796, test accuracy: 74.81\n",
      "Epoch: 31, train loss: 0.6990509202575683, train accuracy: 85.468, test loss: 0.9504462427139282, test accuracy: 71.08\n",
      "Epoch: 32, train loss: 0.7092040707397461, train accuracy: 85.158, test loss: 0.89952058801651, test accuracy: 74.45\n",
      "Epoch: 33, train loss: 0.709478939666748, train accuracy: 85.496, test loss: 0.9194023533821106, test accuracy: 74.69\n",
      "Epoch: 34, train loss: 0.6267356795501708, train accuracy: 89.812, test loss: 0.7832713044166565, test accuracy: 80.69\n",
      "Epoch: 35, train loss: 0.6043500019836425, train accuracy: 90.998, test loss: 0.7734292687416077, test accuracy: 81.16\n",
      "Epoch: 36, train loss: 0.5953112285614014, train accuracy: 91.288, test loss: 0.7770956919670104, test accuracy: 80.71\n",
      "Epoch: 37, train loss: 0.5901914323425292, train accuracy: 91.586, test loss: 0.7750853693008423, test accuracy: 80.75\n",
      "Epoch: 38, train loss: 0.5864381867980957, train accuracy: 91.798, test loss: 0.7871419234275818, test accuracy: 80.28\n",
      "Epoch: 39, train loss: 0.583138006362915, train accuracy: 92.036, test loss: 0.7774148291587829, test accuracy: 80.65\n",
      "Epoch: 40, train loss: 0.5784497343444824, train accuracy: 92.28, test loss: 0.7868086183547973, test accuracy: 79.99\n",
      "Epoch: 41, train loss: 0.5648243146514893, train accuracy: 92.926, test loss: 0.7797863897323608, test accuracy: 80.59\n",
      "Epoch: 42, train loss: 0.5615984662628174, train accuracy: 93.088, test loss: 0.7759477979660034, test accuracy: 80.65\n",
      "Epoch: 43, train loss: 0.559516079788208, train accuracy: 93.27, test loss: 0.777813980960846, test accuracy: 80.59\n",
      "Epoch: 44, train loss: 0.5617314249420166, train accuracy: 93.146, test loss: 0.7799862415313721, test accuracy: 80.53\n",
      "Epoch: 45, train loss: 0.5600968579101563, train accuracy: 93.308, test loss: 0.7788109891891479, test accuracy: 80.54\n",
      "Epoch: 46, train loss: 0.5585655310058594, train accuracy: 93.352, test loss: 0.7803557181358337, test accuracy: 80.74\n",
      "Epoch: 47, train loss: 0.5573506011962891, train accuracy: 93.376, test loss: 0.7765292405128479, test accuracy: 80.55\n",
      "Epoch: 48, train loss: 0.5568101706695556, train accuracy: 93.344, test loss: 0.7774504875183106, test accuracy: 80.5\n",
      "Epoch: 49, train loss: 0.5574208100128174, train accuracy: 93.432, test loss: 0.7797323794364929, test accuracy: 80.61\n",
      "Model doesn't improve, early stop\n"
     ]
    }
   ],
   "source": [
    "def get_loaders(batch_size=128, num_workers=2, transform=transforms.ToTensor()):\n",
    "    train = datasets.CIFAR10('../data', train=True, download=True, transform=transform)\n",
    "    test = datasets.CIFAR10('../data', train=False, download=True, transform=transform)\n",
    "    torch.manual_seed(123)  # To ensure the same sampling during each experiment\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "epochs = 80\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_loader, test_loader = get_loaders(batch_size=batch_size, transform=transform, num_workers=0)\n",
    "model = ResNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay = 0.1, amsgrad = True)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max', patience = 4)\n",
    "\n",
    "min_loss = 100\n",
    "max_early_stop = 15\n",
    "early_stop = 0\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_accuracy = train(model, device, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = test(model, device, test_loader)\n",
    "    scheduler.step(test_accuracy)\n",
    "\n",
    "    #early stop\n",
    "    if test_loss > min_loss:\n",
    "        early_stop += 1\n",
    "    else:\n",
    "        min_loss = test_loss\n",
    "        early_stop = 0\n",
    "    if early_stop == max_early_stop:\n",
    "        print(\"Model doesn't improve, early stop\")\n",
    "        break\n",
    "\n",
    "\n",
    "    print(\"Epoch: {}, train loss: {}, train accuracy: {}, test loss: {}, test accuracy: {}\".format(epoch, train_loss, train_accuracy, test_loss, test_accuracy))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты для гиперпараметров, подобранных вручную"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 0, train loss: 1.3474447024536134, train accuracy: 51.226, test loss: 1.2984502500534059, test accuracy: 52.88\n",
      "Epoch: 1, train loss: 1.0135837547302247, train accuracy: 64.374, test loss: 1.2190793561935425, test accuracy: 54.42\n",
      "Epoch: 2, train loss: 0.9013457600402832, train accuracy: 68.854, test loss: 1.2080781826019287, test accuracy: 56.4\n",
      "Epoch: 3, train loss: 0.8272447872924805, train accuracy: 71.954, test loss: 1.0307086879730225, test accuracy: 62.95\n",
      "Epoch: 4, train loss: 0.7656343673706054, train accuracy: 74.294, test loss: 0.9496164835929871, test accuracy: 67.33\n",
      "Epoch: 5, train loss: 0.7219563063812255, train accuracy: 75.976, test loss: 0.9451825685501098, test accuracy: 67.42\n",
      "Epoch: 6, train loss: 0.6874327080535889, train accuracy: 77.25, test loss: 0.926943623828888, test accuracy: 67.9\n",
      "Epoch: 7, train loss: 0.6707906939697266, train accuracy: 77.758, test loss: 0.8636785765647889, test accuracy: 70.49\n",
      "Epoch: 8, train loss: 0.6404652870178222, train accuracy: 79.03, test loss: 0.8464522529602051, test accuracy: 71.45\n",
      "Epoch: 9, train loss: 0.6330224672698974, train accuracy: 79.218, test loss: 0.8047463840484619, test accuracy: 72.44\n",
      "Epoch: 10, train loss: 0.6156269860839844, train accuracy: 79.746, test loss: 0.9268719172477722, test accuracy: 69.5\n",
      "Epoch: 11, train loss: 0.6018303134155274, train accuracy: 80.462, test loss: 0.7641596132278442, test accuracy: 74.43\n",
      "Epoch: 12, train loss: 0.5915837139129638, train accuracy: 80.732, test loss: 0.7096852346420288, test accuracy: 76.11\n",
      "Epoch: 13, train loss: 0.5859026122283936, train accuracy: 80.922, test loss: 0.8505204195022583, test accuracy: 71.02\n",
      "Epoch: 14, train loss: 0.5798000808715821, train accuracy: 81.326, test loss: 0.9329956190109253, test accuracy: 69.45\n",
      "Epoch: 15, train loss: 0.5700429159545899, train accuracy: 81.508, test loss: 0.8433826313018798, test accuracy: 72.37\n",
      "Epoch: 16, train loss: 0.563593822479248, train accuracy: 81.8, test loss: 0.8185473862648011, test accuracy: 72.64\n",
      "Epoch: 17, train loss: 0.5599743203735351, train accuracy: 81.804, test loss: 0.8366756206512451, test accuracy: 71.5\n",
      "Epoch: 18, train loss: 0.5503128580474853, train accuracy: 82.26, test loss: 0.7318125479698181, test accuracy: 75.36\n",
      "Epoch: 19, train loss: 0.40312974964141846, train accuracy: 88.196, test loss: 0.4762838997364044, test accuracy: 84.6\n",
      "Epoch: 20, train loss: 0.3511853126907349, train accuracy: 89.878, test loss: 0.4710508244514465, test accuracy: 84.75\n",
      "Epoch: 21, train loss: 0.32686048828125, train accuracy: 90.624, test loss: 0.46846395196914675, test accuracy: 84.8\n",
      "Epoch: 22, train loss: 0.30454650512695314, train accuracy: 91.516, test loss: 0.46113481750488283, test accuracy: 85.0\n",
      "Epoch: 23, train loss: 0.28703014743804933, train accuracy: 92.156, test loss: 0.46758058233261107, test accuracy: 85.05\n",
      "Epoch: 24, train loss: 0.27181374515533446, train accuracy: 92.624, test loss: 0.4665339949607849, test accuracy: 84.77\n",
      "Epoch: 25, train loss: 0.2584474219322205, train accuracy: 93.218, test loss: 0.46880806760787963, test accuracy: 84.91\n",
      "Epoch: 26, train loss: 0.24172390964508056, train accuracy: 93.818, test loss: 0.4883315854549408, test accuracy: 84.06\n",
      "Epoch: 27, train loss: 0.22979614517211913, train accuracy: 94.276, test loss: 0.4831486359119415, test accuracy: 84.12\n",
      "Epoch: 28, train loss: 0.21837198585510254, train accuracy: 94.724, test loss: 0.4780710757255554, test accuracy: 84.49\n",
      "Epoch: 29, train loss: 0.20870913928985596, train accuracy: 95.11, test loss: 0.4849533752441406, test accuracy: 83.96\n",
      "Epoch: 30, train loss: 0.16702308908462524, train accuracy: 96.802, test loss: 0.4676224063873291, test accuracy: 84.5\n",
      "Epoch: 31, train loss: 0.15802552062988282, train accuracy: 97.296, test loss: 0.47000905842781066, test accuracy: 84.64\n",
      "Epoch: 32, train loss: 0.15541009757995605, train accuracy: 97.346, test loss: 0.47141489005088805, test accuracy: 84.51\n",
      "Epoch: 33, train loss: 0.15179767011642456, train accuracy: 97.534, test loss: 0.47211934504508973, test accuracy: 84.51\n",
      "Epoch: 34, train loss: 0.15089889446258545, train accuracy: 97.574, test loss: 0.47337789959907534, test accuracy: 84.56\n",
      "Epoch: 35, train loss: 0.14738661106109618, train accuracy: 97.694, test loss: 0.4730863302230835, test accuracy: 84.49\n",
      "Epoch: 36, train loss: 0.14255974420547485, train accuracy: 97.904, test loss: 0.47394814624786374, test accuracy: 84.43\n",
      "Model doesn't improve, early stop\n"
     ]
    }
   ],
   "source": [
    "def get_loaders(batch_size=128, num_workers=2, transform=transforms.ToTensor()):\n",
    "    train = datasets.CIFAR10('../data', train=True, download=True, transform=transform)\n",
    "    test = datasets.CIFAR10('../data', train=False, download=True, transform=transform)\n",
    "    torch.manual_seed(123)  # To ensure the same sampling during each experiment\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "epochs = 80\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_loader, test_loader = get_loaders(batch_size=batch_size, transform=transform, num_workers=0)\n",
    "model = ResNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay = 0.01, amsgrad = True)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max', patience = 5)\n",
    "\n",
    "min_loss = 100\n",
    "max_early_stop = 15\n",
    "early_stop = 0\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_accuracy = train(model, device, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = test(model, device, test_loader)\n",
    "    scheduler.step(test_accuracy)\n",
    "\n",
    "    #early stop\n",
    "    if test_loss > min_loss:\n",
    "        early_stop += 1\n",
    "    else:\n",
    "        min_loss = test_loss\n",
    "        early_stop = 0\n",
    "    if early_stop == max_early_stop:\n",
    "        print(\"Model doesn't improve, early stop\")\n",
    "        break\n",
    "\n",
    "\n",
    "    print(\"Epoch: {}, train loss: {}, train accuracy: {}, test loss: {}, test accuracy: {}\".format(epoch, train_loss, train_accuracy, test_loss, test_accuracy))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поиск гиперпараметров на части датасета не дает тех же результатов на всем датасете. Необходимо искать гиперпараметры на всем датасете, но это занимает слигком много времени (больше двух дней)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework_04.ipynb",
   "provenance": [
    {
     "file_id": "1TQGHBzOzOe0E74RpT3GzrWMyJZ3C8YKc",
     "timestamp": 1612619639922
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
