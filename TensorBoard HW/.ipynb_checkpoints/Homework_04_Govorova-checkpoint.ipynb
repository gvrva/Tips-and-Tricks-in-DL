{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbGec4tuFg6-"
   },
   "source": [
    "# Tensorboard and Optuna\n",
    "\n",
    "* PyTorch [website](https://pytorch.org/)\n",
    "* PyTorch [Tutorials](https://pytorch.org/tutorials/)\n",
    "* TensorBoard [website](https://www.tensorflow.org/tensorboard)\n",
    "* PyTorch [Tensorboard](https://pytorch.org/docs/stable/tensorboard.html) docs\n",
    "* PyTorch TensorBoard [Tutorial](https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUDm-ClcZmKs"
   },
   "source": [
    "# TensorBoard\n",
    "Load the TensorBoard notebook extension\n",
    "\n",
    "*Enable 3rd party cookies in your browser settings. Use Google Chrome.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "8p3Tbx8cWEFA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 21892), started 20:03:45 ago. (Use '!kill 21892' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-64ed9a3718f71b80\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-64ed9a3718f71b80\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "logs_dir = './logs/'\n",
    "%tensorboard --logdir {logs_dir} --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "aF6PfGxJaTk0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"rm\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "#!rm -r {logs_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VG-GsdpUB_Y-"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# writer = SummaryWriter(log_dir=logs_dir+'experiment_02', flush_secs=2)\n",
    "\n",
    "# for epoch in range(1, 100):\n",
    "#     writer.add_scalar('Loss/train', np.random.random()/epoch, epoch)\n",
    "#     writer.add_scalar('Loss/test', np.random.random()/epoch, epoch)\n",
    "#     writer.add_scalar('Accuracy/train', np.random.random()*epoch, epoch)\n",
    "#     writer.add_scalar('Accuracy/test', np.random.random()*epoch, epoch)\n",
    "#     time.sleep(0.25)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2a7FqaIkdd7"
   },
   "source": [
    "## Homework 04\n",
    "\n",
    "\n",
    "All tasks could be done together.\n",
    "1. (3) Use Optuna to tune hyperparameters. Decrease error rate of your best original model (Homework 03) by 20% at least. (E.g., your best model accuracy was 85%, the error rate was 100%-85%=15%; hence, you need to find hyperparameters to achieve 100%-15%*(100%-80%)=88% accuracy)\n",
    "2. (1) Use TensorBoard to log each model training process (Train and Val loss and accuracy) (*.add_scalar*) and save hyperparameters of each model examined by Optuna (*.add_hparams*).\n",
    "3. (1) Save visualization of each model architecture examined by Optuna to TensorBoard. (*.add_graph*)\n",
    "4. \\* (2) Save up to 3 misclassified images from the test dataset of each class of each model architecture examined by Optuna to TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(batch_size=128, num_workers=2, transform=transforms.ToTensor()):\n",
    "    train = datasets.CIFAR10('../data', train=True, download=True, transform=transform)\n",
    "    test = datasets.CIFAR10('../data', train=False, download=True, transform=transform)\n",
    "    torch.manual_seed(123)  # To ensure the same sampling during each experiment\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        #ResNet\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        #Residual block 1\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(16)\n",
    "        self.conv5 = nn.Conv2d(in_channels=16, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(16)\n",
    "        \n",
    "        \n",
    "        #Residual block 2\n",
    "        self.conv6 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(32)\n",
    "        self.conv7 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv8 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv9 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn9 = nn.BatchNorm2d(32)\n",
    "        self.conv10 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn10 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        \n",
    "        #Residual block 3\n",
    "        self.conv11 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn11 = nn.BatchNorm2d(64)\n",
    "        self.conv12 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn12 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv13 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn13 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv14 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn14 = nn.BatchNorm2d(64)\n",
    "        self.conv15 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn15 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        \n",
    "        #Final\n",
    "        self.pool = nn.AvgPool2d(8)\n",
    "        self.fc = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        \n",
    "        #Residual block 1\n",
    "        \n",
    "        residual = x\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x += residual\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        residual = x\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x += residual\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        \n",
    "        #Residual block 2\n",
    "        \n",
    "        residual = x\n",
    "        x = self.conv6(x)\n",
    "        x = self.bn6(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.conv7(x)\n",
    "        x = self.bn7(x)\n",
    "        residual = self.conv8(residual)\n",
    "        residual = self.bn8(residual)\n",
    "        x += residual\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        residual = x\n",
    "        x = self.conv9(x)\n",
    "        x = self.bn9(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.conv10(x)\n",
    "        x = self.bn10(x)\n",
    "        x += residual\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        \n",
    "        #Residual block 3\n",
    "        \n",
    "        residual = x\n",
    "        x = self.conv11(x)\n",
    "        x = self.bn11(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.conv12(x)\n",
    "        x = self.bn12(x)\n",
    "        residual = self.conv13(residual)\n",
    "        residual = self.bn13(residual)\n",
    "        x += residual\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        residual = x\n",
    "        x = self.conv14(x)\n",
    "        x = self.bn14(x)\n",
    "        x = F.relu(x, inplace=True)\n",
    "        x = self.conv15(x)\n",
    "        x = self.bn15(x)\n",
    "        x += residual\n",
    "        x = F.relu(x, inplace=True)\n",
    "        \n",
    "        \n",
    "        #Final\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        x = F.log_softmax(x, 1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in train_loader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += F.nll_loss(out, target, reduction='sum').item()\n",
    "        \n",
    "        _, predicted = torch.max(out, 1)\n",
    "        correct += (predicted == target).sum().item()\n",
    "    \n",
    "    return train_loss / len(train_loader.dataset), 100*correct/len(train_loader.dataset)\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            out = model(data)\n",
    "            loss = F.nll_loss(out, target, reduction='sum')\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            _, predicted = torch.max(out, 1)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "    return test_loss / len(test_loader.dataset), 100*correct/len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Результаты обучения с исходными гиперпараметрами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 0, train loss: 1.3198433351135255, train accuracy: 52.152, test loss: 1.1042257577896117, test accuracy: 60.43\n",
      "Epoch: 1, train loss: 0.9174589726257324, train accuracy: 67.116, test loss: 1.1893796867370605, test accuracy: 58.72\n",
      "Epoch: 2, train loss: 0.7514306256866455, train accuracy: 73.244, test loss: 0.986364881515503, test accuracy: 65.92\n",
      "Epoch: 3, train loss: 0.6434364685821533, train accuracy: 77.396, test loss: 0.832281383895874, test accuracy: 71.85\n",
      "Epoch: 4, train loss: 0.5700424662780762, train accuracy: 79.976, test loss: 0.6637911425590515, test accuracy: 77.3\n",
      "Epoch: 5, train loss: 0.5098514769744873, train accuracy: 82.178, test loss: 0.6829347948074341, test accuracy: 75.82\n",
      "Epoch: 6, train loss: 0.45761971324920653, train accuracy: 83.934, test loss: 0.7763535768508911, test accuracy: 74.88\n",
      "Epoch: 7, train loss: 0.40921455169677734, train accuracy: 85.714, test loss: 0.7343721952438355, test accuracy: 76.52\n",
      "Epoch: 8, train loss: 0.3679293466567993, train accuracy: 87.162, test loss: 0.6576082370758056, test accuracy: 78.53\n",
      "Epoch: 9, train loss: 0.3346932698059082, train accuracy: 88.3, test loss: 0.6462885419845581, test accuracy: 78.52\n",
      "Epoch: 10, train loss: 0.29542499557495117, train accuracy: 89.742, test loss: 0.816597548866272, test accuracy: 75.83\n",
      "Epoch: 11, train loss: 0.2610422516441345, train accuracy: 91.014, test loss: 0.7322241855621338, test accuracy: 77.74\n",
      "Epoch: 12, train loss: 0.23199411520004273, train accuracy: 91.846, test loss: 0.7220434261322022, test accuracy: 78.56\n",
      "Epoch: 13, train loss: 0.2059470022201538, train accuracy: 92.778, test loss: 0.719095069026947, test accuracy: 78.58\n",
      "Epoch: 14, train loss: 0.17852938968658447, train accuracy: 93.706, test loss: 0.840555110359192, test accuracy: 77.73\n",
      "Epoch: 15, train loss: 0.15947624282836914, train accuracy: 94.364, test loss: 0.8301676169395447, test accuracy: 77.55\n",
      "Epoch: 16, train loss: 0.14202616108894348, train accuracy: 95.052, test loss: 0.791912149810791, test accuracy: 79.12\n",
      "Epoch: 17, train loss: 0.12748216426849365, train accuracy: 95.62, test loss: 0.8666488533020019, test accuracy: 77.05\n",
      "Epoch: 18, train loss: 0.11315415128707886, train accuracy: 96.11, test loss: 0.8426686117172241, test accuracy: 79.45\n",
      "Epoch: 19, train loss: 0.10293813051223755, train accuracy: 96.478, test loss: 0.9820581447601319, test accuracy: 76.43\n",
      "Epoch: 20, train loss: 0.09009743715286254, train accuracy: 96.932, test loss: 1.0606310539245605, test accuracy: 75.92\n",
      "Epoch: 21, train loss: 0.09337100776195525, train accuracy: 96.722, test loss: 0.8498806447982789, test accuracy: 80.15\n",
      "Epoch: 22, train loss: 0.07807551862716675, train accuracy: 97.306, test loss: 1.2050905479431153, test accuracy: 75.25\n",
      "Epoch: 23, train loss: 0.0759982504415512, train accuracy: 97.418, test loss: 0.9656620729446411, test accuracy: 78.5\n",
      "Model doesn't improve, early stop\n"
     ]
    }
   ],
   "source": [
    "epochs = 80\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "batch_size = 128\n",
    "lr = 1e-3\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_loader, test_loader = get_loaders(batch_size=batch_size, transform=transform, num_workers=0)\n",
    "model = ResNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max')\n",
    "\n",
    "min_loss = 100\n",
    "max_early_stop = 15\n",
    "early_stop = 0\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_accuracy = train(model, device, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = test(model, device, test_loader)\n",
    "    scheduler.step(test_accuracy)\n",
    "\n",
    "    #early stop\n",
    "    if test_loss > min_loss:\n",
    "        early_stop += 1\n",
    "    else:\n",
    "        min_loss = test_loss\n",
    "        early_stop = 0\n",
    "    if early_stop == max_early_stop:\n",
    "        print(\"Model doesn't improve, early stop\")\n",
    "        break\n",
    "\n",
    "\n",
    "    print(\"Epoch: {}, train loss: {}, train accuracy: {}, test loss: {}, test accuracy: {}\".format(epoch, train_loss, train_accuracy, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(100%-78%)*0.2 = 4.4%\n",
    "Требуется увеличить значение точности на 4.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск оптимальных гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split_len = 10000\n",
    "test_split_len = 4000\n",
    "\n",
    "def get_loaders_batch(batch_size=128, num_workers=2, transform=transforms.ToTensor()):\n",
    "    train = datasets.CIFAR10('../data', train=True, download=True, transform=transform)\n",
    "    test = datasets.CIFAR10('../data', train=False, download=True, transform=transform)\n",
    "    torch.manual_seed(123)  # To ensure the same sampling during each experiment\n",
    "    train = torch.utils.data.random_split(train, [train_split_len, len(train)-train_split_len])[0]\n",
    "    test = torch.utils.data.random_split(test, [test_split_len, len(test)-test_split_len])[0]\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты на части датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 0, train loss: 2.141661865234375, train accuracy: 21.25, test loss: 2.322151611328125, test accuracy: 8.875\n",
      "Epoch: 1, train loss: 1.7917584716796875, train accuracy: 34.19, test loss: 2.7609059448242186, test accuracy: 11.325\n",
      "Epoch: 2, train loss: 1.6402809814453125, train accuracy: 40.01, test loss: 2.9300391845703126, test accuracy: 11.3\n",
      "Epoch: 3, train loss: 1.5237365478515625, train accuracy: 44.03, test loss: 2.747302062988281, test accuracy: 15.05\n",
      "Epoch: 4, train loss: 1.4361932373046875, train accuracy: 47.87, test loss: 2.5305416259765625, test accuracy: 19.675\n",
      "Epoch: 5, train loss: 1.3608674682617188, train accuracy: 50.57, test loss: 1.7043411254882812, test accuracy: 40.025\n",
      "Epoch: 6, train loss: 1.3018899291992188, train accuracy: 52.91, test loss: 2.24929931640625, test accuracy: 28.025\n",
      "Epoch: 7, train loss: 1.23191181640625, train accuracy: 55.72, test loss: 1.6827589111328125, test accuracy: 40.425\n",
      "Epoch: 8, train loss: 1.1704461791992187, train accuracy: 58.41, test loss: 1.5464143981933594, test accuracy: 43.85\n",
      "Epoch: 9, train loss: 1.1216389892578125, train accuracy: 60.08, test loss: 1.4446582336425782, test accuracy: 49.875\n",
      "Epoch: 10, train loss: 1.0505271850585938, train accuracy: 63.21, test loss: 1.4960868530273437, test accuracy: 47.075\n",
      "Epoch: 11, train loss: 0.9887413696289062, train accuracy: 65.75, test loss: 1.3888539733886718, test accuracy: 50.075\n",
      "Epoch: 12, train loss: 0.9252081726074218, train accuracy: 67.92, test loss: 1.3594306640625, test accuracy: 50.15\n",
      "Epoch: 13, train loss: 0.8728948608398438, train accuracy: 70.51, test loss: 1.335561767578125, test accuracy: 52.65\n",
      "Epoch: 14, train loss: 0.8089361145019531, train accuracy: 73.0, test loss: 1.336952850341797, test accuracy: 53.825\n",
      "Epoch: 15, train loss: 0.7694878479003906, train accuracy: 74.63, test loss: 1.2798568725585937, test accuracy: 56.475\n",
      "Epoch: 16, train loss: 0.700049853515625, train accuracy: 77.87, test loss: 1.2414060974121093, test accuracy: 58.05\n",
      "Epoch: 17, train loss: 0.6404486938476562, train accuracy: 80.35, test loss: 1.3876883850097657, test accuracy: 53.15\n",
      "Epoch: 18, train loss: 0.5822294189453125, train accuracy: 82.71, test loss: 1.2534046325683594, test accuracy: 56.05\n",
      "Epoch: 19, train loss: 0.53472568359375, train accuracy: 84.24, test loss: 1.7931797180175781, test accuracy: 45.625\n",
      "Epoch: 20, train loss: 0.5019199432373047, train accuracy: 85.63, test loss: 1.4396996459960938, test accuracy: 53.275\n",
      "Epoch: 21, train loss: 0.4342321228027344, train accuracy: 88.56, test loss: 1.3835128479003906, test accuracy: 53.425\n",
      "Epoch: 22, train loss: 0.39475619201660156, train accuracy: 90.07, test loss: 1.5143123474121094, test accuracy: 51.125\n",
      "Epoch: 23, train loss: 0.34289273681640625, train accuracy: 92.07, test loss: 1.5299137573242187, test accuracy: 52.35\n",
      "Epoch: 24, train loss: 0.29486265869140627, train accuracy: 93.74, test loss: 1.4069974060058594, test accuracy: 54.825\n",
      "Epoch: 25, train loss: 0.2580943328857422, train accuracy: 94.81, test loss: 1.481246826171875, test accuracy: 52.9\n",
      "Epoch: 26, train loss: 0.21923724212646484, train accuracy: 96.4, test loss: 1.4312935791015624, test accuracy: 56.35\n",
      "Epoch: 27, train loss: 0.18463933258056642, train accuracy: 97.19, test loss: 1.485475341796875, test accuracy: 55.775\n",
      "Epoch: 28, train loss: 0.1391607276916504, train accuracy: 98.71, test loss: 1.4474791564941407, test accuracy: 55.3\n",
      "Epoch: 29, train loss: 0.11917319946289062, train accuracy: 99.16, test loss: 1.3944548950195312, test accuracy: 55.55\n",
      "Epoch: 30, train loss: 0.11128245849609375, train accuracy: 99.33, test loss: 1.3663571166992188, test accuracy: 57.825\n",
      "Model doesn't improve, early stop\n"
     ]
    }
   ],
   "source": [
    "epochs = 80\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "batch_size = 1500\n",
    "lr = 1e-3\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_loader, test_loader = get_loaders_batch(batch_size=batch_size, transform=transform, num_workers=0)\n",
    "model = ResNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max')\n",
    "\n",
    "min_loss = 128\n",
    "max_early_stop = 15\n",
    "early_stop = 0\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_accuracy = train(model, device, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = test(model, device, test_loader)\n",
    "    scheduler.step(test_accuracy)\n",
    "\n",
    "    #early stop\n",
    "    if test_loss > min_loss:\n",
    "        early_stop += 1\n",
    "    else:\n",
    "        min_loss = test_loss\n",
    "        early_stop = 0\n",
    "    if early_stop == max_early_stop:\n",
    "        print(\"Model doesn't improve, early stop\")\n",
    "        break\n",
    "\n",
    "\n",
    "    print(\"Epoch: {}, train loss: {}, train accuracy: {}, test loss: {}, test accuracy: {}\".format(epoch, train_loss, train_accuracy, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#отдельная функция трейна с эпохами\n",
    "\n",
    "def epoch_train(model, params, trial_n):\n",
    "    \n",
    "    experiment = 'trial_'+str(trial_n)\n",
    "    writer = SummaryWriter(log_dir=logs_dir+experiment, flush_secs=2)\n",
    "    \n",
    "    epochs = 80\n",
    "    max_early_stop = 15\n",
    "    min_loss = 100\n",
    "    early_stop = 0\n",
    "    batch_size = 1500\n",
    "    \n",
    "    lr = params[\"lr\"]\n",
    "    weight_decay = params[\"weight_decay\"]\n",
    "    amsgrad = params[\"amsgrad\"]\n",
    "    patience = params[\"patience\"]\n",
    "    \n",
    "    train_loader, test_loader = get_loaders_batch(batch_size=batch_size, transform=transform, num_workers=0)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay = weight_decay, amsgrad = amsgrad)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'max', patience = patience)\n",
    "    \n",
    "    accuracy = 0\n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_accuracy = train(model, device, train_loader, optimizer)\n",
    "        test_loss, test_accuracy = test(model, device, test_loader)\n",
    "        scheduler.step(test_accuracy)\n",
    "        \n",
    "        writer.add_scalar('Loss/train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/test', test_loss, epoch)\n",
    "        writer.add_scalar('Accuracy/train', train_accuracy, epoch)\n",
    "        writer.add_scalar('Accuracy/test', test_accuracy, epoch)\n",
    "\n",
    "        #early stop\n",
    "        if test_loss > min_loss:\n",
    "            early_stop += 1\n",
    "        else:\n",
    "            min_loss = test_loss\n",
    "            early_stop = 0\n",
    "        if early_stop == max_early_stop:\n",
    "            print(\"Model doesn't improve, early stop\")\n",
    "            accuracy = test_accuracy\n",
    "            break\n",
    "        if epoch==epochs-1:\n",
    "            accuracy = test_accuracy\n",
    "    \n",
    "    writer.add_hparams(hparam_dict = params, metric_dict = {'accuracy':accuracy})\n",
    "    writer.close()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "6iwPRszakdeG"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    model = ResNet().to(device)\n",
    "    \n",
    "    amsgrad = trial.suggest_categorical(\"amsgrad\",[True, False])\n",
    "    lr = trial.suggest_categorical(\"lr\", [1e-5, 1e-4, 1e-3, 1e-2, 1e-1])\n",
    "    weight_decay = trial.suggest_categorical(\"weight_decay\", [0, 1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1])\n",
    "    patience = trial.suggest_int(\"patience\", 4, 10)\n",
    "    \n",
    "    params = {\"lr\":lr, \"weight_decay\":weight_decay, \"amsgrad\": amsgrad, \"patience\": patience}\n",
    "    \n",
    "    accuracy = epoch_train(model, params, trial.number)\n",
    "    \n",
    "    print(accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 17:13:12,629]\u001b[0m A new study created in memory with name: no-name-6ef50447-e555-426c-b14f-b0adada735d2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 17:20:41,242]\u001b[0m Trial 0 finished with value: 67.775 and parameters: {'amsgrad': True, 'lr': 0.01, 'weight_decay': 1e-07, 'patience': 9}. Best is trial 0 with value: 67.775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "67.775\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 17:32:27,872]\u001b[0m Trial 1 finished with value: 36.975 and parameters: {'amsgrad': True, 'lr': 1e-05, 'weight_decay': 0.0001, 'patience': 6}. Best is trial 0 with value: 67.775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.975\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 17:41:21,949]\u001b[0m Trial 2 finished with value: 60.25 and parameters: {'amsgrad': False, 'lr': 0.1, 'weight_decay': 0.0001, 'patience': 10}. Best is trial 0 with value: 67.775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "60.25\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 17:47:18,622]\u001b[0m Trial 3 finished with value: 59.925 and parameters: {'amsgrad': False, 'lr': 0.001, 'weight_decay': 1e-07, 'patience': 6}. Best is trial 0 with value: 67.775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "59.925\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 17:53:16,425]\u001b[0m Trial 4 finished with value: 56.325 and parameters: {'amsgrad': True, 'lr': 0.01, 'weight_decay': 1e-07, 'patience': 7}. Best is trial 0 with value: 67.775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "56.325\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 18:03:14,877]\u001b[0m Trial 5 finished with value: 18.375 and parameters: {'amsgrad': True, 'lr': 0.1, 'weight_decay': 0.1, 'patience': 7}. Best is trial 0 with value: 67.775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "18.375\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 18:08:53,257]\u001b[0m Trial 6 finished with value: 60.65 and parameters: {'amsgrad': False, 'lr': 0.001, 'weight_decay': 1e-05, 'patience': 5}. Best is trial 0 with value: 67.775.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "60.65\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 18:16:07,824]\u001b[0m Trial 7 finished with value: 69.5 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.0001, 'patience': 4}. Best is trial 7 with value: 69.5.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "69.5\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 18:28:05,181]\u001b[0m Trial 8 finished with value: 55.525 and parameters: {'amsgrad': False, 'lr': 0.0001, 'weight_decay': 0.0001, 'patience': 8}. Best is trial 7 with value: 69.5.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.525\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 18:39:39,299]\u001b[0m Trial 9 finished with value: 58.6 and parameters: {'amsgrad': True, 'lr': 0.0001, 'weight_decay': 0.01, 'patience': 6}. Best is trial 7 with value: 69.5.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.6\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 18:46:30,802]\u001b[0m Trial 10 finished with value: 71.725 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "71.725\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 18:55:34,052]\u001b[0m Trial 11 finished with value: 65.6 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "65.6\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 19:03:09,820]\u001b[0m Trial 12 finished with value: 67.875 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "67.875\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 19:10:01,378]\u001b[0m Trial 13 finished with value: 67.825 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 1e-06, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "67.825\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 19:17:55,173]\u001b[0m Trial 14 finished with value: 64.825 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 5}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "64.825\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 19:29:29,998]\u001b[0m Trial 15 finished with value: 40.875 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 0.001, 'patience': 5}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.875\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 19:39:08,403]\u001b[0m Trial 16 finished with value: 65.025 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.01, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "65.025\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 19:50:17,094]\u001b[0m Trial 17 finished with value: 36.8 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.1, 'patience': 5}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "36.8\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 20:01:52,520]\u001b[0m Trial 18 finished with value: 53.775 and parameters: {'amsgrad': False, 'lr': 0.1, 'weight_decay': 1e-05, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.775\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 20:13:25,142]\u001b[0m Trial 19 finished with value: 57.8 and parameters: {'amsgrad': False, 'lr': 0.0001, 'weight_decay': 0, 'patience': 8}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.8\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 20:19:29,318]\u001b[0m Trial 20 finished with value: 61.375 and parameters: {'amsgrad': False, 'lr': 0.001, 'weight_decay': 1e-06, 'patience': 5}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "61.375\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 20:27:07,736]\u001b[0m Trial 21 finished with value: 68.825 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "68.825\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 20:34:54,199]\u001b[0m Trial 22 finished with value: 67.05 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "67.05\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 20:42:53,838]\u001b[0m Trial 23 finished with value: 67.925 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0, 'patience': 5}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "67.925\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 20:50:29,279]\u001b[0m Trial 24 finished with value: 70.775 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.0001, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "70.775\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 21:02:03,817]\u001b[0m Trial 25 finished with value: 39.925 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 0.0001, 'patience': 6}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.925\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 21:09:52,983]\u001b[0m Trial 26 finished with value: 71.525 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.0001, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "71.525\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 21:17:22,550]\u001b[0m Trial 27 finished with value: 68.5 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.0001, 'patience': 5}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "68.5\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 21:26:27,546]\u001b[0m Trial 28 finished with value: 67.325 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 6}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "67.325\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 21:34:05,358]\u001b[0m Trial 29 finished with value: 69.825 and parameters: {'amsgrad': True, 'lr': 0.01, 'weight_decay': 0.0001, 'patience': 9}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "69.825\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 21:40:51,625]\u001b[0m Trial 30 finished with value: 70.2 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "70.2\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 21:48:42,660]\u001b[0m Trial 31 finished with value: 65.725 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "65.725\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 21:55:59,881]\u001b[0m Trial 32 finished with value: 69.1 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 5}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "69.1\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 22:02:33,222]\u001b[0m Trial 33 finished with value: 70.0 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "70.0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 22:14:11,919]\u001b[0m Trial 34 finished with value: 41.375 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 0.0001, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.375\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 22:25:33,805]\u001b[0m Trial 35 finished with value: 57.75 and parameters: {'amsgrad': False, 'lr': 0.1, 'weight_decay': 1e-07, 'patience': 5}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "57.75\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 22:31:15,913]\u001b[0m Trial 36 finished with value: 60.125 and parameters: {'amsgrad': True, 'lr': 0.001, 'weight_decay': 0.0001, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "60.125\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 22:38:50,605]\u001b[0m Trial 37 finished with value: 69.825 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 6}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "69.825\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 22:50:31,151]\u001b[0m Trial 38 finished with value: 40.675 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.1, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.675\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 22:57:47,682]\u001b[0m Trial 39 finished with value: 48.325 and parameters: {'amsgrad': True, 'lr': 0.1, 'weight_decay': 1e-05, 'patience': 10}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "48.325\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 23:09:28,275]\u001b[0m Trial 40 finished with value: 56.05 and parameters: {'amsgrad': False, 'lr': 0.0001, 'weight_decay': 0.0001, 'patience': 7}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.05\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 23:17:20,949]\u001b[0m Trial 41 finished with value: 71.35 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "71.35\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 23:25:14,009]\u001b[0m Trial 42 finished with value: 69.075 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 5}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "69.075\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 23:34:07,670]\u001b[0m Trial 43 finished with value: 64.725 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "64.725\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 23:41:59,748]\u001b[0m Trial 44 finished with value: 70.275 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "70.275\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 23:50:03,514]\u001b[0m Trial 45 finished with value: 68.1 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 1e-07, 'patience': 5}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "68.1\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-02 23:56:14,870]\u001b[0m Trial 46 finished with value: 61.225 and parameters: {'amsgrad': False, 'lr': 0.001, 'weight_decay': 0.01, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "61.225\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-03 00:02:54,813]\u001b[0m Trial 47 finished with value: 67.225 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.0001, 'patience': 5}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "67.225\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-03 00:10:25,549]\u001b[0m Trial 48 finished with value: 70.3 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 1e-06, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "70.3\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-03 00:17:13,330]\u001b[0m Trial 49 finished with value: 68.425 and parameters: {'amsgrad': True, 'lr': 0.01, 'weight_decay': 1e-06, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "68.425\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-03 00:28:54,662]\u001b[0m Trial 50 finished with value: 40.975 and parameters: {'amsgrad': False, 'lr': 1e-05, 'weight_decay': 1e-06, 'patience': 5}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40.975\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-03 00:35:54,719]\u001b[0m Trial 51 finished with value: 68.675 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 1e-06, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "68.675\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-03 00:44:03,470]\u001b[0m Trial 52 finished with value: 68.7 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "68.7\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-03 00:50:36,494]\u001b[0m Trial 53 finished with value: 66.6 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 1e-06, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "66.6\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-03 00:58:08,689]\u001b[0m Trial 54 finished with value: 70.0 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "70.0\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-03 01:09:43,039]\u001b[0m Trial 55 finished with value: 56.05 and parameters: {'amsgrad': False, 'lr': 0.0001, 'weight_decay': 0.1, 'patience': 5}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.05\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-03 01:16:15,151]\u001b[0m Trial 56 finished with value: 69.025 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.0001, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "69.025\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-03 01:24:22,169]\u001b[0m Trial 57 finished with value: 69.525 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 1e-05, 'patience': 8}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "69.525\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-03 01:33:21,125]\u001b[0m Trial 58 finished with value: 66.05 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.01, 'patience': 5}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "66.05\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-03-03 01:42:46,244]\u001b[0m Trial 59 finished with value: 65.35 and parameters: {'amsgrad': False, 'lr': 0.01, 'weight_decay': 0.001, 'patience': 4}. Best is trial 10 with value: 71.725.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model doesn't improve, early stop\n",
      "65.35\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials = 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперпараметры, выдающие лучший результат согласно тестам optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(batch_size=128, num_workers=2, transform=transforms.ToTensor()):\n",
    "    train = datasets.CIFAR10('../data', train=True, download=True, transform=transform)\n",
    "    test = datasets.CIFAR10('../data', train=False, download=True, transform=transform)\n",
    "    torch.manual_seed(123)  # To ensure the same sampling during each experiment\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch: 0, train loss: 1.9842961401367187, train accuracy: 24.394, test loss: 1.9445603637695312, test accuracy: 27.61\n",
      "Epoch: 1, train loss: 1.6038608068847657, train accuracy: 39.682, test loss: 2.9688794189453125, test accuracy: 18.33\n",
      "Epoch: 2, train loss: 1.3838228686523437, train accuracy: 49.03, test loss: 2.70900595703125, test accuracy: 26.76\n",
      "Epoch: 3, train loss: 1.1870370275878905, train accuracy: 57.112, test loss: 1.6661898803710937, test accuracy: 39.91\n",
      "Epoch: 4, train loss: 1.04872478515625, train accuracy: 62.384, test loss: 1.4851636840820313, test accuracy: 49.4\n",
      "Epoch: 5, train loss: 0.9413260284423828, train accuracy: 66.484, test loss: 1.4462117797851564, test accuracy: 49.71\n",
      "Epoch: 6, train loss: 0.8621785192871094, train accuracy: 69.376, test loss: 2.21353056640625, test accuracy: 32.05\n",
      "Epoch: 7, train loss: 0.7834112194824219, train accuracy: 72.386, test loss: 1.4390924926757813, test accuracy: 53.15\n",
      "Epoch: 8, train loss: 0.7220015509033203, train accuracy: 74.79, test loss: 1.1282299438476562, test accuracy: 60.53\n",
      "Epoch: 9, train loss: 0.6767298168945313, train accuracy: 76.286, test loss: 0.861273291015625, test accuracy: 69.94\n",
      "Epoch: 10, train loss: 0.6225940435791015, train accuracy: 78.496, test loss: 0.803591748046875, test accuracy: 72.0\n",
      "Epoch: 11, train loss: 0.5846671453857422, train accuracy: 79.842, test loss: 1.2519316284179687, test accuracy: 59.8\n",
      "Epoch: 12, train loss: 0.5632886022949218, train accuracy: 80.398, test loss: 0.8143923950195312, test accuracy: 71.91\n",
      "Epoch: 13, train loss: 0.5459507275390625, train accuracy: 81.208, test loss: 0.9316227111816406, test accuracy: 68.63\n",
      "Epoch: 14, train loss: 0.5313983609008789, train accuracy: 81.56, test loss: 1.0238952514648438, test accuracy: 65.6\n",
      "Epoch: 15, train loss: 0.5078391333007812, train accuracy: 82.462, test loss: 0.9892283020019531, test accuracy: 67.65\n",
      "Epoch: 16, train loss: 0.378603268737793, train accuracy: 87.586, test loss: 0.4975253692626953, test accuracy: 83.02\n",
      "Epoch: 17, train loss: 0.29836924346923827, train accuracy: 90.326, test loss: 0.4901102691650391, test accuracy: 83.59\n",
      "Epoch: 18, train loss: 0.26139448028564455, train accuracy: 91.76, test loss: 0.48700288391113283, test accuracy: 83.6\n",
      "Epoch: 19, train loss: 0.23173530136108397, train accuracy: 92.97, test loss: 0.5276220947265625, test accuracy: 82.23\n",
      "Epoch: 20, train loss: 0.2080881153869629, train accuracy: 93.906, test loss: 0.4970581634521484, test accuracy: 83.42\n",
      "Epoch: 21, train loss: 0.18221054794311523, train accuracy: 94.898, test loss: 0.5231321838378906, test accuracy: 82.64\n",
      "Epoch: 22, train loss: 0.16266565994262697, train accuracy: 95.694, test loss: 0.5377295959472657, test accuracy: 82.07\n",
      "Epoch: 23, train loss: 0.14197129364013672, train accuracy: 96.512, test loss: 0.5895975219726562, test accuracy: 80.7\n",
      "Epoch: 24, train loss: 0.1047726789855957, train accuracy: 98.144, test loss: 0.5138801940917969, test accuracy: 83.33\n",
      "Epoch: 25, train loss: 0.09276184616088867, train accuracy: 98.606, test loss: 0.5175911102294922, test accuracy: 83.27\n",
      "Epoch: 26, train loss: 0.0884132544708252, train accuracy: 98.762, test loss: 0.5191945129394532, test accuracy: 83.24\n",
      "Epoch: 27, train loss: 0.08511260581970215, train accuracy: 98.87, test loss: 0.5250257202148437, test accuracy: 83.33\n",
      "Epoch: 28, train loss: 0.0822385344696045, train accuracy: 98.952, test loss: 0.5281840850830078, test accuracy: 83.26\n",
      "Epoch: 29, train loss: 0.07878774993896484, train accuracy: 99.06, test loss: 0.527939974975586, test accuracy: 83.26\n",
      "Epoch: 30, train loss: 0.07822634078979492, train accuracy: 99.052, test loss: 0.5281923522949219, test accuracy: 83.19\n",
      "Epoch: 31, train loss: 0.07776132278442383, train accuracy: 99.086, test loss: 0.5285222198486328, test accuracy: 83.22\n",
      "Epoch: 32, train loss: 0.07760992012023926, train accuracy: 99.06, test loss: 0.5295444030761719, test accuracy: 83.2\n",
      "Model doesn't improve, early stop\n"
     ]
    }
   ],
   "source": [
    "epochs = 80\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "batch_size = 1500\n",
    "\n",
    "transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_loader, test_loader = get_loaders(batch_size=batch_size, transform=transform, num_workers=0)\n",
    "model = ResNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay = 0.001, amsgrad = False)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'max', patience = 4)\n",
    "\n",
    "min_loss = 100\n",
    "max_early_stop = 15\n",
    "early_stop = 0\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_accuracy = train(model, device, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = test(model, device, test_loader)\n",
    "    scheduler.step(test_accuracy)\n",
    "\n",
    "    #early stop\n",
    "    if test_loss > min_loss:\n",
    "        early_stop += 1\n",
    "    else:\n",
    "        min_loss = test_loss\n",
    "        early_stop = 0\n",
    "    if early_stop == max_early_stop:\n",
    "        print(\"Model doesn't improve, early stop\")\n",
    "        break\n",
    "\n",
    "\n",
    "    print(\"Epoch: {}, train loss: {}, train accuracy: {}, test loss: {}, test accuracy: {}\".format(epoch, train_loss, train_accuracy, test_loss, test_accuracy))            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гиперпараметры, подобранные на части датасета, дали увеличение точности и на всем датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework_04.ipynb",
   "provenance": [
    {
     "file_id": "1TQGHBzOzOe0E74RpT3GzrWMyJZ3C8YKc",
     "timestamp": 1612619639922
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
